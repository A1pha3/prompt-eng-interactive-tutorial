# é—®é¢˜æ’æŸ¥

## ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [ç›®æ ‡è¯»è€…](#ç›®æ ‡è¯»è€…)
- [é—®é¢˜è¯Šæ–­æµç¨‹](#é—®é¢˜è¯Šæ–­æµç¨‹)
- [å¸¸è§é—®é¢˜åˆ†ç±»](#å¸¸è§é—®é¢˜åˆ†ç±»)
- [API å’Œè¿æ¥é—®é¢˜](#api-å’Œè¿æ¥é—®é¢˜)
- [æç¤ºå’Œè¾“å‡ºé—®é¢˜](#æç¤ºå’Œè¾“å‡ºé—®é¢˜)
- [æ€§èƒ½é—®é¢˜](#æ€§èƒ½é—®é¢˜)
- [è´¨é‡é—®é¢˜](#è´¨é‡é—®é¢˜)
- [æˆæœ¬é—®é¢˜](#æˆæœ¬é—®é¢˜)
- [è°ƒè¯•æŠ€å·§å’Œå·¥å…·](#è°ƒè¯•æŠ€å·§å’Œå·¥å…·)
- [è·å–å¸®åŠ©](#è·å–å¸®åŠ©)
- [ç›¸å…³èµ„æº](#ç›¸å…³èµ„æº)

---

## æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›ç³»ç»ŸåŒ–çš„é—®é¢˜æ’æŸ¥æŒ‡å—ï¼Œå¸®åŠ©æ‚¨å¿«é€Ÿè¯†åˆ«å’Œè§£å†³ä½¿ç”¨ Claude æ—¶é‡åˆ°çš„å„ç§é—®é¢˜ã€‚æ— è®ºæ˜¯ API é”™è¯¯ã€è¾“å‡ºè´¨é‡é—®é¢˜è¿˜æ˜¯æ€§èƒ½ç“¶é¢ˆï¼Œæ‚¨éƒ½èƒ½åœ¨è¿™é‡Œæ‰¾åˆ°è§£å†³æ–¹æ¡ˆã€‚

---

## ç›®æ ‡è¯»è€…

æœ¬æ–‡æ¡£é€‚åˆä»¥ä¸‹äººç¾¤ï¼š

- **å¼€å‘è€…**ï¼šé‡åˆ°æŠ€æœ¯é—®é¢˜éœ€è¦å¿«é€Ÿè§£å†³
- **ç³»ç»Ÿç®¡ç†å‘˜**ï¼šç»´æŠ¤ç”Ÿäº§ç¯å¢ƒä¸­çš„ AI åº”ç”¨
- **æµ‹è¯•äººå‘˜**ï¼šéªŒè¯å’Œè°ƒè¯• AI åŠŸèƒ½
- **æ‰€æœ‰ç”¨æˆ·**ï¼šé‡åˆ°ä»»ä½•ä½¿ç”¨é—®é¢˜

---

## é—®é¢˜è¯Šæ–­æµç¨‹

### ç³»ç»ŸåŒ–è¯Šæ–­æ–¹æ³•

```
1. è¯†åˆ«é—®é¢˜
   â†“
2. æ”¶é›†ä¿¡æ¯
   â†“
3. éš”ç¦»å˜é‡
   â†“
4. æµ‹è¯•å‡è®¾
   â†“
5. å®æ–½è§£å†³æ–¹æ¡ˆ
   â†“
6. éªŒè¯ä¿®å¤
   â†“
7. è®°å½•ç»éªŒ
```

### é—®é¢˜è¯†åˆ«æ¸…å•

åœ¨å¼€å§‹æ’æŸ¥å‰ï¼Œæ˜ç¡®ä»¥ä¸‹é—®é¢˜ï¼š

- [ ] é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆå…·ä½“ç—‡çŠ¶ï¼‰
- [ ] ä½•æ—¶å¼€å§‹å‡ºç°ï¼Ÿï¼ˆæ—¶é—´ç‚¹ï¼‰
- [ ] æ˜¯å¦èƒ½ç¨³å®šå¤ç°ï¼Ÿï¼ˆé¢‘ç‡ï¼‰
- [ ] å½±å“èŒƒå›´ï¼Ÿï¼ˆæ‰€æœ‰è¯·æ±‚è¿˜æ˜¯ç‰¹å®šæƒ…å†µï¼‰
- [ ] æœ€è¿‘æœ‰ä»€ä¹ˆå˜åŒ–ï¼Ÿï¼ˆä»£ç ã€é…ç½®ã€æ•°æ®ï¼‰
- [ ] é”™è¯¯ä¿¡æ¯æ˜¯ä»€ä¹ˆï¼Ÿï¼ˆå®Œæ•´çš„é”™è¯¯æ—¥å¿—ï¼‰

### ä¿¡æ¯æ”¶é›†

**å¿…è¦ä¿¡æ¯**ï¼š
```python
# è®°å½•è¯·æ±‚è¯¦æƒ…
debug_info = {
    "timestamp": datetime.now(),
    "model": "claude-3-haiku-20240307",
    "prompt_length": len(prompt),
    "max_tokens": 1024,
    "temperature": 0.0,
    "error_message": str(error),
    "request_id": response.headers.get("request-id")
}
```

---

## å¸¸è§é—®é¢˜åˆ†ç±»

### é—®é¢˜ç±»å‹æ¦‚è§ˆ

| ç±»å‹ | å¸¸è§ç—‡çŠ¶ | ç´§æ€¥ç¨‹åº¦ |
|------|----------|----------|
| API é”™è¯¯ | è¯·æ±‚å¤±è´¥ã€è¶…æ—¶ | ğŸ”´ é«˜ |
| è¾“å‡ºè´¨é‡ | ç»“æœä¸å‡†ç¡®ã€æ ¼å¼é”™è¯¯ | ğŸŸ¡ ä¸­ |
| æ€§èƒ½é—®é¢˜ | å“åº”æ…¢ã€è¶…æ—¶ | ğŸŸ¡ ä¸­ |
| æˆæœ¬é—®é¢˜ | è´¹ç”¨è¶…é¢„æœŸ | ğŸŸ¢ ä½ |
| é…ç½®é—®é¢˜ | è®¤è¯å¤±è´¥ã€æƒé™é”™è¯¯ | ğŸ”´ é«˜ |

---

## API å’Œè¿æ¥é—®é¢˜

### é—®é¢˜ 1ï¼šè®¤è¯å¤±è´¥

**ç—‡çŠ¶**ï¼š
```
anthropic.AuthenticationError: Invalid API key
```

**åŸå› **ï¼š
- API å¯†é’¥é”™è¯¯æˆ–è¿‡æœŸ
- API å¯†é’¥æ ¼å¼ä¸æ­£ç¡®
- ç¯å¢ƒå˜é‡æœªæ­£ç¡®è®¾ç½®

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ­¥éª¤ 1ï¼šéªŒè¯ API å¯†é’¥**
```python
# æ£€æŸ¥ API å¯†é’¥æ ¼å¼
API_KEY = "sk-ant-..."  # åº”è¯¥ä»¥ sk-ant- å¼€å¤´

# æµ‹è¯• API å¯†é’¥
import anthropic

try:
    client = anthropic.Anthropic(api_key=API_KEY)
    message = client.messages.create(
        model="claude-3-haiku-20240307",
        max_tokens=10,
        messages=[{"role": "user", "content": "Hi"}]
    )
    print("âœ… API å¯†é’¥æœ‰æ•ˆ")
except anthropic.AuthenticationError:
    print("âŒ API å¯†é’¥æ— æ•ˆ")
```

**æ­¥éª¤ 2ï¼šæ£€æŸ¥ç¯å¢ƒå˜é‡**
```bash
# æŸ¥çœ‹ç¯å¢ƒå˜é‡
echo $ANTHROPIC_API_KEY

# è®¾ç½®ç¯å¢ƒå˜é‡
export ANTHROPIC_API_KEY="your_api_key_here"
```

**æ­¥éª¤ 3ï¼šé‡æ–°ç”Ÿæˆå¯†é’¥**
- è®¿é—® [Anthropic Console](https://console.anthropic.com/)
- ç”Ÿæˆæ–°çš„ API å¯†é’¥
- æ›´æ–°åº”ç”¨é…ç½®

### é—®é¢˜ 2ï¼šè¯·æ±‚è¶…æ—¶

**ç—‡çŠ¶**ï¼š
```
requests.exceptions.Timeout: Request timed out
```

**åŸå› **ï¼š
- ç½‘ç»œè¿æ¥ä¸ç¨³å®š
- æç¤ºè¿‡é•¿å¯¼è‡´å¤„ç†æ—¶é—´é•¿
- æœåŠ¡å™¨è´Ÿè½½é«˜

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ 1ï¼šå¢åŠ è¶…æ—¶æ—¶é—´**
```python
client = anthropic.Anthropic(
    api_key=API_KEY,
    timeout=60.0  # å¢åŠ åˆ° 60 ç§’
)
```

**æ–¹æ¡ˆ 2ï¼šä½¿ç”¨é‡è¯•æœºåˆ¶**
```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=10)
)
def call_claude_with_retry(prompt):
    return client.messages.create(
        model="claude-3-haiku-20240307",
        max_tokens=1024,
        messages=[{"role": "user", "content": prompt}]
    )
```

**æ–¹æ¡ˆ 3ï¼šä¼˜åŒ–æç¤ºé•¿åº¦**
```python
# å¦‚æœæç¤ºè¿‡é•¿ï¼Œè€ƒè™‘åˆ†æ®µå¤„ç†
if len(prompt) > 10000:
    # åˆ†æ®µæˆ–æ€»ç»“
    prompt = summarize_prompt(prompt)
```

### é—®é¢˜ 3ï¼šé€Ÿç‡é™åˆ¶

**ç—‡çŠ¶**ï¼š
```
anthropic.RateLimitError: Rate limit exceeded
```

**åŸå› **ï¼š
- è¯·æ±‚é¢‘ç‡è¶…è¿‡é™åˆ¶
- å¹¶å‘è¯·æ±‚è¿‡å¤š
- Token ä½¿ç”¨è¶…è¿‡é…é¢

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ 1ï¼šå®ç°é€Ÿç‡é™åˆ¶**
```python
import time
from collections import deque

class RateLimiter:
    def __init__(self, max_requests_per_minute=50):
        self.max_requests = max_requests_per_minute
        self.requests = deque()
    
    def wait_if_needed(self):
        now = time.time()
        # ç§»é™¤ 1 åˆ†é’Ÿå‰çš„è¯·æ±‚è®°å½•
        while self.requests and self.requests[0] < now - 60:
            self.requests.popleft()
        
        # å¦‚æœè¾¾åˆ°é™åˆ¶ï¼Œç­‰å¾…
        if len(self.requests) >= self.max_requests:
            sleep_time = 60 - (now - self.requests[0])
            time.sleep(sleep_time)
        
        self.requests.append(now)

limiter = RateLimiter(max_requests_per_minute=50)

def call_claude_with_limit(prompt):
    limiter.wait_if_needed()
    return client.messages.create(...)
```

**æ–¹æ¡ˆ 2ï¼šä½¿ç”¨æŒ‡æ•°é€€é¿**
```python
import time

def call_with_backoff(prompt, max_retries=5):
    for i in range(max_retries):
        try:
            return client.messages.create(...)
        except anthropic.RateLimitError:
            if i == max_retries - 1:
                raise
            wait_time = 2 ** i  # 1, 2, 4, 8, 16 ç§’
            print(f"é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’...")
            time.sleep(wait_time)
```

### é—®é¢˜ 4ï¼šç½‘ç»œè¿æ¥é”™è¯¯

**ç—‡çŠ¶**ï¼š
```
requests.exceptions.ConnectionError: Failed to establish connection
```

**åŸå› **ï¼š
- ç½‘ç»œä¸ç¨³å®š
- é˜²ç«å¢™é˜»æ­¢
- DNS è§£æé—®é¢˜
- ä»£ç†é…ç½®é—®é¢˜

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ 1ï¼šæ£€æŸ¥ç½‘ç»œè¿æ¥**
```bash
# æµ‹è¯•è¿æ¥
ping api.anthropic.com

# æµ‹è¯• HTTPS è¿æ¥
curl -I https://api.anthropic.com
```

**æ–¹æ¡ˆ 2ï¼šé…ç½®ä»£ç†**
```python
import os

# è®¾ç½®ä»£ç†
os.environ['HTTP_PROXY'] = 'http://proxy.example.com:8080'
os.environ['HTTPS_PROXY'] = 'http://proxy.example.com:8080'

# æˆ–åœ¨å®¢æˆ·ç«¯ä¸­é…ç½®
import httpx

client = anthropic.Anthropic(
    api_key=API_KEY,
    http_client=httpx.Client(proxies="http://proxy.example.com:8080")
)
```

**æ–¹æ¡ˆ 3ï¼šä½¿ç”¨å¤‡ç”¨ DNS**
```bash
# ä¿®æ”¹ /etc/hosts (Linux/Mac)
# æˆ– C:\Windows\System32\drivers\etc\hosts (Windows)
# æ·»åŠ ï¼š
# 8.8.8.8 api.anthropic.com
```

### é—®é¢˜ 5ï¼šAWS Bedrock ç‰¹å®šé—®é¢˜

**ç—‡çŠ¶**ï¼š
```
botocore.exceptions.NoCredentialsError: Unable to locate credentials
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ­¥éª¤ 1ï¼šé…ç½® AWS å‡­è¯**
```bash
aws configure
# è¾“å…¥ Access Key ID
# è¾“å…¥ Secret Access Key
# è¾“å…¥ Region (å¦‚ us-east-1)
```

**æ­¥éª¤ 2ï¼šéªŒè¯å‡­è¯**
```bash
aws sts get-caller-identity
```

**æ­¥éª¤ 3ï¼šæ£€æŸ¥ Bedrock è®¿é—®æƒé™**
```bash
aws bedrock list-foundation-models --region us-east-1
```

**æ­¥éª¤ 4ï¼šè¯·æ±‚æ¨¡å‹è®¿é—®**
- è®¿é—® AWS Console
- è¿›å…¥ Bedrock æœåŠ¡
- è¯·æ±‚ Claude æ¨¡å‹è®¿é—®æƒé™

---

## æç¤ºå’Œè¾“å‡ºé—®é¢˜

### é—®é¢˜ 6ï¼šè¾“å‡ºè¢«æˆªæ–­

**ç—‡çŠ¶**ï¼š
- å“åº”çªç„¶ç»“æŸ
- å¥å­ä¸å®Œæ•´
- ç¼ºå°‘é¢„æœŸå†…å®¹

**åŸå› **ï¼š
- `max_tokens` è®¾ç½®è¿‡å°
- è¾“å‡ºè¶…è¿‡æ¨¡å‹é™åˆ¶

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ 1ï¼šå¢åŠ  max_tokens**
```python
# âŒ å¤ªå°
response = client.messages.create(
    model="claude-3-haiku-20240307",
    max_tokens=100,  # å¯èƒ½ä¸å¤Ÿ
    messages=[{"role": "user", "content": "å†™ä¸€ç¯‡æ–‡ç« ..."}]
)

# âœ… åˆç†è®¾ç½®
response = client.messages.create(
    model="claude-3-haiku-20240307",
    max_tokens=2048,  # æ ¹æ®éœ€æ±‚è°ƒæ•´
    messages=[{"role": "user", "content": "å†™ä¸€ç¯‡æ–‡ç« ..."}]
)
```

**æ–¹æ¡ˆ 2ï¼šæ£€æŸ¥ stop_reason**
```python
response = client.messages.create(...)

if response.stop_reason == "max_tokens":
    print("âš ï¸ è¾“å‡ºè¢«æˆªæ–­ï¼Œéœ€è¦å¢åŠ  max_tokens")
elif response.stop_reason == "end_turn":
    print("âœ… è¾“å‡ºå®Œæ•´")
```

**æ–¹æ¡ˆ 3ï¼šåˆ†æ®µç”Ÿæˆ**
```python
# å¯¹äºé•¿å†…å®¹ï¼Œåˆ†æ®µç”Ÿæˆ
sections = ["å¼•è¨€", "ä¸»ä½“", "ç»“è®º"]
full_content = ""

for section in sections:
    response = client.messages.create(
        model="claude-3-haiku-20240307",
        max_tokens=1024,
        messages=[{
            "role": "user",
            "content": f"å†™æ–‡ç« çš„{section}éƒ¨åˆ†ï¼š{full_content}"
        }]
    )
    full_content += response.content[0].text
```

### é—®é¢˜ 7ï¼šè¾“å‡ºæ ¼å¼ä¸ä¸€è‡´

**ç—‡çŠ¶**ï¼š
- æœ‰æ—¶è¿”å› JSONï¼Œæœ‰æ—¶è¿”å›æ–‡æœ¬
- æ ¼å¼ä¸ç¬¦åˆé¢„æœŸ
- åŒ…å«ä¸å¿…è¦çš„å‰è¨€

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ 1ï¼šä½¿ç”¨é¢„å¡«å……**
```python
messages = [
    {"role": "user", "content": "åˆ—å‡ºä¸‰ç§æ°´æœ"},
    {"role": "assistant", "content": "{"}  # å¼ºåˆ¶ JSON æ ¼å¼
]
```

**æ–¹æ¡ˆ 2ï¼šæ˜ç¡®æ ¼å¼è¦æ±‚**
```python
PROMPT = """
åˆ†æä»¥ä¸‹æ–‡æœ¬ï¼Œä»¥ JSON æ ¼å¼è¾“å‡ºã€‚

<text>
{text}
</text>

è¾“å‡ºæ ¼å¼ï¼ˆä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼‰ï¼š
{{
  "sentiment": "positive/negative/neutral",
  "keywords": ["keyword1", "keyword2"]
}}
"""
```

**æ–¹æ¡ˆ 3ï¼šåå¤„ç†éªŒè¯**
```python
import json
import re

def extract_json(response_text):
    # å°è¯•ç›´æ¥è§£æ
    try:
        return json.loads(response_text)
    except:
        pass
    
    # å°è¯•æå– JSON éƒ¨åˆ†
    json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
    if json_match:
        try:
            return json.loads(json_match.group())
        except:
            pass
    
    raise ValueError("æ— æ³•æå–æœ‰æ•ˆçš„ JSON")

response_text = response.content[0].text
data = extract_json(response_text)
```

### é—®é¢˜ 8ï¼šClaude ä¸éµå¾ªæŒ‡ä»¤

**ç—‡çŠ¶**ï¼š
- è¾“å‡ºä¸è¦æ±‚ä¸ç¬¦
- å¿½ç•¥æŸäº›çº¦æŸ
- æ·»åŠ ä¸å¿…è¦çš„å†…å®¹

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ 1ï¼šä½¿ç”¨æ›´æ¸…æ™°çš„æŒ‡ä»¤**
```python
# âŒ æ¨¡ç³Š
PROMPT = "åˆ†æè¿™ä¸ªæ–‡æœ¬"

# âœ… æ¸…æ™°
PROMPT = """
åˆ†æä»¥ä¸‹æ–‡æœ¬ï¼Œåªæä¾›ä»¥ä¸‹ä¿¡æ¯ï¼š
1. ä¸»é¢˜ï¼ˆä¸€å¥è¯ï¼‰
2. æƒ…æ„Ÿï¼ˆæ­£é¢/è´Ÿé¢/ä¸­æ€§ï¼‰
3. å…³é”®è¯ï¼ˆ3-5ä¸ªï¼‰

ä¸è¦åŒ…å«å…¶ä»–å†…å®¹ã€‚

<text>
{text}
</text>
"""
```

**æ–¹æ¡ˆ 2ï¼šä½¿ç”¨ç³»ç»Ÿæç¤ºå¼ºåŒ–**
```python
SYSTEM_PROMPT = """
ä½ å¿…é¡»ä¸¥æ ¼éµå¾ªç”¨æˆ·çš„æŒ‡ä»¤ã€‚
- åªè¾“å‡ºè¦æ±‚çš„å†…å®¹
- ä¸è¦æ·»åŠ è§£é‡Šæˆ–å‰è¨€
- ä¸¥æ ¼æŒ‰ç…§æŒ‡å®šæ ¼å¼è¾“å‡º
"""
```

**æ–¹æ¡ˆ 3ï¼šä½¿ç”¨é¢„å¡«å……**
```python
messages = [
    {"role": "user", "content": "åˆ—å‡ºä¸‰ç§æ°´æœï¼Œä¸è¦å…¶ä»–å†…å®¹"},
    {"role": "assistant", "content": "1."}  # å¼•å¯¼ç›´æ¥è¾“å‡º
]
```

### é—®é¢˜ 9ï¼šè¾“å‡ºåŒ…å«å¹»è§‰

**ç—‡çŠ¶**ï¼š
- ç¼–é€ ä¸å­˜åœ¨çš„äº‹å®
- è™šæ„å¼•ç”¨æˆ–æ•°æ®
- å¯¹ä¸ç¡®å®šçš„ä¿¡æ¯è¡¨ç°å¾—å¾ˆç¡®å®š

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ 1ï¼šæä¾›å®Œæ•´ä¸Šä¸‹æ–‡**
```python
# âŒ ä¾èµ–æ¨¡å‹è®°å¿†
PROMPT = "æ€»ç»“ã€ŠXYZæŠ¥å‘Šã€‹çš„ä¸»è¦å‘ç°"

# âœ… æä¾›å®é™…å†…å®¹
PROMPT = """
æ€»ç»“ä»¥ä¸‹æŠ¥å‘Šçš„ä¸»è¦å‘ç°ï¼š

<report>
[æŠ¥å‘Šå…¨æ–‡]
</report>

åªåŸºäºä¸Šè¿°å†…å®¹è¿›è¡Œæ€»ç»“ï¼Œä¸è¦æ·»åŠ æŠ¥å‘Šä¸­æ²¡æœ‰çš„ä¿¡æ¯ã€‚
"""
```

**æ–¹æ¡ˆ 2ï¼šè¦æ±‚å¼•ç”¨æ¥æº**
```python
PROMPT = """
å›ç­”é—®é¢˜å¹¶å¼•ç”¨æ–‡æ¡£ä¸­çš„å…·ä½“å†…å®¹ï¼š

<document>
{document}
</document>

é—®é¢˜ï¼š{question}

è¦æ±‚ï¼š
- ç›´æ¥å¼•ç”¨æ–‡æ¡£ä¸­çš„ç›¸å…³å¥å­
- ä½¿ç”¨å¼•å·æ ‡æ³¨å¼•ç”¨
- å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œæ˜ç¡®è¯´æ˜"æ–‡æ¡£ä¸­æœªæåŠ"
"""
```

**æ–¹æ¡ˆ 3ï¼šè¦æ±‚æ‰¿è®¤ä¸ç¡®å®šæ€§**
```python
SYSTEM_PROMPT = """
åœ¨å›ç­”æ—¶ï¼š
- å¦‚æœä¸ç¡®å®šï¼Œæ˜ç¡®è¯´"æˆ‘ä¸ç¡®å®š"
- åŒºåˆ†äº‹å®å’Œæ¨æµ‹
- ä¸è¦ç¼–é€ ä¿¡æ¯
- æ‰¿è®¤çŸ¥è¯†çš„å±€é™æ€§
"""
```

---

## æ€§èƒ½é—®é¢˜

### é—®é¢˜ 10ï¼šå“åº”æ—¶é—´è¿‡é•¿

**ç—‡çŠ¶**ï¼š
- è¯·æ±‚éœ€è¦å¾ˆé•¿æ—¶é—´æ‰èƒ½å®Œæˆ
- è¶…è¿‡é¢„æœŸçš„å“åº”æ—¶é—´

**è¯Šæ–­æ­¥éª¤**ï¼š

**æ­¥éª¤ 1ï¼šæµ‹é‡å„éƒ¨åˆ†æ—¶é—´**
```python
import time

start_time = time.time()

# ç½‘ç»œæ—¶é—´
request_start = time.time()
response = client.messages.create(...)
request_end = time.time()

# å¤„ç†æ—¶é—´
process_start = time.time()
result = process_response(response)
process_end = time.time()

print(f"ç½‘ç»œæ—¶é—´: {request_end - request_start:.2f}s")
print(f"å¤„ç†æ—¶é—´: {process_end - process_start:.2f}s")
print(f"æ€»æ—¶é—´: {time.time() - start_time:.2f}s")
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ 1ï¼šä¼˜åŒ–æç¤ºé•¿åº¦**
```python
# å‡å°‘è¾“å…¥ tokens
prompt = optimize_prompt(original_prompt)
```

**æ–¹æ¡ˆ 2ï¼šä½¿ç”¨æ›´å¿«çš„æ¨¡å‹**
```python
# Haiku æ¯” Opus å¿«å¾—å¤š
model = "claude-3-haiku-20240307"  # è€Œä¸æ˜¯ opus
```

**æ–¹æ¡ˆ 3ï¼šä½¿ç”¨æµå¼è¾“å‡º**
```python
# è·å¾—æ›´å¿«çš„é¦–å­—èŠ‚æ—¶é—´
with client.messages.stream(...) as stream:
    for text in stream.text_stream:
        print(text, end="", flush=True)
```

**æ–¹æ¡ˆ 4ï¼šå¹¶è¡Œå¤„ç†**
```python
# å¯¹äºå¤šä¸ªç‹¬ç«‹è¯·æ±‚ï¼Œå¹¶è¡Œå¤„ç†
import asyncio

async def process_batch(items):
    tasks = [process_item(item) for item in items]
    return await asyncio.gather(*tasks)
```

### é—®é¢˜ 11ï¼šToken ä½¿ç”¨è¶…å‡ºé¢„æœŸ

**ç—‡çŠ¶**ï¼š
- API è´¹ç”¨é«˜äºé¢„æœŸ
- Token è®¡æ•°ä¸é¢„æœŸä¸ç¬¦

**è¯Šæ–­**ï¼š

```python
response = client.messages.create(...)

print(f"è¾“å…¥ tokens: {response.usage.input_tokens}")
print(f"è¾“å‡º tokens: {response.usage.output_tokens}")
print(f"æ€» tokens: {response.usage.input_tokens + response.usage.output_tokens}")

# ä¼°ç®—æˆæœ¬ï¼ˆä»¥ Haiku ä¸ºä¾‹ï¼‰
input_cost = response.usage.input_tokens * 0.00025 / 1000
output_cost = response.usage.output_tokens * 0.00125 / 1000
total_cost = input_cost + output_cost
print(f"ä¼°ç®—æˆæœ¬: ${total_cost:.4f}")
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ 1ï¼šä¼˜åŒ–æç¤º**
- ç§»é™¤å†—ä½™å†…å®¹
- ä½¿ç”¨æ›´ç®€æ´çš„è¡¨è¾¾
- é¿å…é‡å¤ä¿¡æ¯

**æ–¹æ¡ˆ 2ï¼šæ§åˆ¶è¾“å‡ºé•¿åº¦**
```python
# è®¾ç½®åˆç†çš„ max_tokens
response = client.messages.create(
    max_tokens=500,  # è€Œä¸æ˜¯ 4096
    ...
)
```

**æ–¹æ¡ˆ 3ï¼šä½¿ç”¨ç¼“å­˜**
```python
# ç¼“å­˜å¸¸è§æŸ¥è¯¢çš„ç»“æœ
from functools import lru_cache

@lru_cache(maxsize=1000)
def get_response(prompt):
    return call_claude(prompt)
```

---

## è´¨é‡é—®é¢˜

### é—®é¢˜ 12ï¼šè¾“å‡ºè´¨é‡ä¸ç¨³å®š

**ç—‡çŠ¶**ï¼š
- ç›¸åŒæç¤ºäº§ç”Ÿä¸åŒè´¨é‡çš„è¾“å‡º
- æœ‰æ—¶å¥½æœ‰æ—¶å·®

**åŸå› **ï¼š
- temperature è®¾ç½®è¿‡é«˜
- æç¤ºä¸å¤Ÿæ˜ç¡®
- ç¼ºå°‘ç¤ºä¾‹

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ 1ï¼šè®¾ç½® temperature = 0**
```python
response = client.messages.create(
    temperature=0.0,  # æœ€å¤§åŒ–ä¸€è‡´æ€§
    ...
)
```

**æ–¹æ¡ˆ 2ï¼šæä¾›æ›´æ˜ç¡®çš„æŒ‡ä»¤**
```python
PROMPT = """
ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

æ ¼å¼ï¼š
- ç¬¬ä¸€è¡Œï¼šæ ‡é¢˜
- ç¬¬äºŒè¡Œï¼šæ‘˜è¦ï¼ˆä¸è¶…è¿‡50å­—ï¼‰
- ç¬¬ä¸‰è¡Œå¼€å§‹ï¼šè¯¦ç»†å†…å®¹

ç¤ºä¾‹ï¼š
æ ‡é¢˜ï¼šç¤ºä¾‹æ ‡é¢˜
æ‘˜è¦ï¼šè¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹æ‘˜è¦ï¼Œä¸è¶…è¿‡äº”åå­—ã€‚
è¯¦ç»†å†…å®¹ä»è¿™é‡Œå¼€å§‹...
"""
```

**æ–¹æ¡ˆ 3ï¼šä½¿ç”¨å°‘æ ·æœ¬å­¦ä¹ **
```python
PROMPT = """
ç¤ºä¾‹1ï¼š
è¾“å…¥ï¼š{example1_input}
è¾“å‡ºï¼š{example1_output}

ç¤ºä¾‹2ï¼š
è¾“å…¥ï¼š{example2_input}
è¾“å‡ºï¼š{example2_output}

ç°åœ¨å¤„ç†ï¼š
è¾“å…¥ï¼š{actual_input}
è¾“å‡ºï¼š
"""
```

### é—®é¢˜ 13ï¼šè¾“å‡ºä¸å¤Ÿå‡†ç¡®

**ç—‡çŠ¶**ï¼š
- äº‹å®é”™è¯¯
- é€»è¾‘é”™è¯¯
- ç†è§£åå·®

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ 1ï¼šä½¿ç”¨æ€ç»´é“¾**
```python
PROMPT = """
è¯·é€æ­¥åˆ†æï¼š

1. ç†è§£é—®é¢˜
2. è¯†åˆ«å…³é”®ä¿¡æ¯
3. é€æ­¥æ¨ç†
4. å¾—å‡ºç»“è®º
5. éªŒè¯ç­”æ¡ˆ

é—®é¢˜ï¼š{question}
"""
```

**æ–¹æ¡ˆ 2ï¼šæä¾›æ›´å¤šä¸Šä¸‹æ–‡**
```python
PROMPT = """
<context>
{relevant_context}
</context>

<question>
{question}
</question>

åŸºäºä¸Šè¿°ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚
"""
```

**æ–¹æ¡ˆ 3ï¼šä½¿ç”¨æ›´å¼ºå¤§çš„æ¨¡å‹**
```python
# å¯¹äºå¤æ‚ä»»åŠ¡ï¼Œä½¿ç”¨ Opus
model = "claude-3-opus-20240229"
```

---

## æˆæœ¬é—®é¢˜

### é—®é¢˜ 14ï¼šæˆæœ¬è¶…å‡ºé¢„ç®—

**ç—‡çŠ¶**ï¼š
- API è´¹ç”¨é«˜äºé¢„æœŸ
- æˆæœ¬å¢é•¿è¿‡å¿«

**è¯Šæ–­**ï¼š

```python
# è¿½è¸ªæ¯ä¸ªè¯·æ±‚çš„æˆæœ¬
def track_cost(response, model):
    # Haiku ä»·æ ¼ï¼ˆç¤ºä¾‹ï¼‰
    prices = {
        "claude-3-haiku-20240307": {
            "input": 0.00025 / 1000,
            "output": 0.00125 / 1000
        },
        # å…¶ä»–æ¨¡å‹...
    }
    
    input_cost = response.usage.input_tokens * prices[model]["input"]
    output_cost = response.usage.output_tokens * prices[model]["output"]
    
    return {
        "input_tokens": response.usage.input_tokens,
        "output_tokens": response.usage.output_tokens,
        "input_cost": input_cost,
        "output_cost": output_cost,
        "total_cost": input_cost + output_cost
    }
```

**è§£å†³æ–¹æ¡ˆ**ï¼š

**æ–¹æ¡ˆ 1ï¼šä½¿ç”¨æ›´ç»æµçš„æ¨¡å‹**
```python
# å¯¹äºç®€å•ä»»åŠ¡ï¼Œä½¿ç”¨ Haiku
model = "claude-3-haiku-20240307"  # æœ€ä¾¿å®œ
```

**æ–¹æ¡ˆ 2ï¼šä¼˜åŒ–æç¤ºé•¿åº¦**
- ç§»é™¤ä¸å¿…è¦çš„å†…å®¹
- ä½¿ç”¨æ‘˜è¦è€Œéå…¨æ–‡
- æ‰¹é‡å¤„ç†

**æ–¹æ¡ˆ 3ï¼šå®æ–½æˆæœ¬æ§åˆ¶**
```python
class CostController:
    def __init__(self, daily_budget=10.0):
        self.daily_budget = daily_budget
        self.daily_cost = 0.0
        self.last_reset = datetime.now().date()
    
    def check_budget(self, estimated_cost):
        # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡ç½®
        if datetime.now().date() > self.last_reset:
            self.daily_cost = 0.0
            self.last_reset = datetime.now().date()
        
        # æ£€æŸ¥é¢„ç®—
        if self.daily_cost + estimated_cost > self.daily_budget:
            raise Exception("è¶…å‡ºæ¯æ—¥é¢„ç®—")
        
        self.daily_cost += estimated_cost
```

---

## è°ƒè¯•æŠ€å·§å’Œå·¥å…·

### 1. å¯ç”¨è¯¦ç»†æ—¥å¿—

```python
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# è®°å½•è¯·æ±‚è¯¦æƒ…
logger = logging.getLogger(__name__)

def call_claude_with_logging(prompt):
    logger.info(f"å‘é€è¯·æ±‚ï¼Œæç¤ºé•¿åº¦: {len(prompt)}")
    
    try:
        response = client.messages.create(...)
        logger.info(f"æ”¶åˆ°å“åº”ï¼Œtokens: {response.usage.input_tokens + response.usage.output_tokens}")
        return response
    except Exception as e:
        logger.error(f"è¯·æ±‚å¤±è´¥: {str(e)}")
        raise
```

### 2. ä½¿ç”¨è°ƒè¯•åŒ…è£…å™¨

```python
class DebugClient:
    def __init__(self, client):
        self.client = client
        self.requests = []
    
    def messages_create(self, **kwargs):
        # è®°å½•è¯·æ±‚
        request_info = {
            "timestamp": datetime.now(),
            "model": kwargs.get("model"),
            "prompt_length": len(str(kwargs.get("messages"))),
            "max_tokens": kwargs.get("max_tokens")
        }
        
        try:
            response = self.client.messages.create(**kwargs)
            request_info["success"] = True
            request_info["tokens"] = response.usage.input_tokens + response.usage.output_tokens
            return response
        except Exception as e:
            request_info["success"] = False
            request_info["error"] = str(e)
            raise
        finally:
            self.requests.append(request_info)
    
    def get_stats(self):
        total_requests = len(self.requests)
        successful = sum(1 for r in self.requests if r["success"])
        failed = total_requests - successful
        
        return {
            "total_requests": total_requests,
            "successful": successful,
            "failed": failed,
            "success_rate": successful / total_requests if total_requests > 0 else 0
        }

# ä½¿ç”¨
debug_client = DebugClient(client)
response = debug_client.messages_create(...)
print(debug_client.get_stats())
```

### 3. æç¤ºè°ƒè¯•å·¥å…·

```python
def debug_prompt(prompt):
    """åˆ†ææç¤ºçš„æ½œåœ¨é—®é¢˜"""
    issues = []
    
    # æ£€æŸ¥é•¿åº¦
    if len(prompt) > 10000:
        issues.append("âš ï¸ æç¤ºè¿‡é•¿ï¼Œå¯èƒ½å½±å“æ€§èƒ½")
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«æ˜ç¡®æŒ‡ä»¤
    if "è¯·" not in prompt and "è¾“å‡º" not in prompt:
        issues.append("âš ï¸ ç¼ºå°‘æ˜ç¡®çš„æŒ‡ä»¤åŠ¨è¯")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ ¼å¼è¯´æ˜
    if "æ ¼å¼" not in prompt and "JSON" not in prompt:
        issues.append("ğŸ’¡ è€ƒè™‘æ·»åŠ è¾“å‡ºæ ¼å¼è¯´æ˜")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç¤ºä¾‹
    if "ç¤ºä¾‹" not in prompt and "ä¾‹å¦‚" not in prompt:
        issues.append("ğŸ’¡ è€ƒè™‘æ·»åŠ ç¤ºä¾‹ä»¥æé«˜è´¨é‡")
    
    return issues

# ä½¿ç”¨
issues = debug_prompt(my_prompt)
for issue in issues:
    print(issue)
```

### 4. å“åº”éªŒè¯å·¥å…·

```python
def validate_response(response, expected_format=None, required_fields=None):
    """éªŒè¯å“åº”æ˜¯å¦ç¬¦åˆé¢„æœŸ"""
    validation_results = {
        "valid": True,
        "issues": []
    }
    
    text = response.content[0].text
    
    # æ£€æŸ¥æ˜¯å¦è¢«æˆªæ–­
    if response.stop_reason == "max_tokens":
        validation_results["valid"] = False
        validation_results["issues"].append("å“åº”è¢«æˆªæ–­")
    
    # æ£€æŸ¥æ ¼å¼
    if expected_format == "json":
        try:
            data = json.loads(text)
            
            # æ£€æŸ¥å¿…éœ€å­—æ®µ
            if required_fields:
                for field in required_fields:
                    if field not in data:
                        validation_results["valid"] = False
                        validation_results["issues"].append(f"ç¼ºå°‘å­—æ®µ: {field}")
        except json.JSONDecodeError:
            validation_results["valid"] = False
            validation_results["issues"].append("ä¸æ˜¯æœ‰æ•ˆçš„ JSON")
    
    return validation_results

# ä½¿ç”¨
validation = validate_response(
    response,
    expected_format="json",
    required_fields=["sentiment", "keywords"]
)

if not validation["valid"]:
    print("éªŒè¯å¤±è´¥:")
    for issue in validation["issues"]:
        print(f"  - {issue}")
```

### 5. æ€§èƒ½åˆ†æå·¥å…·

```python
import time
from collections import defaultdict

class PerformanceProfiler:
    def __init__(self):
        self.metrics = defaultdict(list)
    
    def profile(self, name):
        def decorator(func):
            def wrapper(*args, **kwargs):
                start_time = time.time()
                result = func(*args, **kwargs)
                end_time = time.time()
                
                self.metrics[name].append(end_time - start_time)
                return result
            return wrapper
        return decorator
    
    def report(self):
        for name, times in self.metrics.items():
            avg_time = sum(times) / len(times)
            min_time = min(times)
            max_time = max(times)
            
            print(f"{name}:")
            print(f"  å¹³å‡: {avg_time:.2f}s")
            print(f"  æœ€å°: {min_time:.2f}s")
            print(f"  æœ€å¤§: {max_time:.2f}s")
            print(f"  è°ƒç”¨æ¬¡æ•°: {len(times)}")

# ä½¿ç”¨
profiler = PerformanceProfiler()

@profiler.profile("claude_call")
def call_claude(prompt):
    return client.messages.create(...)

# æ‰§è¡Œå¤šæ¬¡è°ƒç”¨
for prompt in prompts:
    call_claude(prompt)

# æŸ¥çœ‹æŠ¥å‘Š
profiler.report()
```

### 6. æ¨èçš„ç¬¬ä¸‰æ–¹å·¥å…·

**ç›‘æ§å’Œåˆ†æ**ï¼š
- **Langfuse**ï¼šLLM åº”ç”¨æ€§èƒ½ç›‘æ§
- **Helicone**ï¼šAPI è°ƒç”¨è¿½è¸ªå’Œåˆ†æ
- **Weights & Biases**ï¼šå®éªŒè¿½è¸ª

**å¼€å‘å·¥å…·**ï¼š
- **Jupyter Notebook**ï¼šäº¤äº’å¼å¼€å‘å’Œè°ƒè¯•
- **Postman**ï¼šAPI æµ‹è¯•
- **curl**ï¼šå‘½ä»¤è¡Œ API æµ‹è¯•

**æ—¥å¿—å’Œé”™è¯¯è¿½è¸ª**ï¼š
- **Sentry**ï¼šé”™è¯¯è¿½è¸ª
- **Datadog**ï¼šåº”ç”¨ç›‘æ§
- **CloudWatch**ï¼šAWS ç¯å¢ƒç›‘æ§

---

## è·å–å¸®åŠ©

### 1. è‡ªåŠ©èµ„æº

**å®˜æ–¹æ–‡æ¡£**ï¼š
- [Anthropic æ–‡æ¡£](https://docs.anthropic.com/)
- [API å‚è€ƒ](https://docs.anthropic.com/claude/reference/)
- [æœ€ä½³å®è·µ](https://docs.anthropic.com/claude/docs/best-practices)

**æœ¬é¡¹ç›®æ–‡æ¡£**ï¼š
- [è®¾è®¡åŸç†](design-principles.md)
- [æ€§èƒ½ä¼˜åŒ–](performance.md)
- [å¸¸è§é—®é¢˜](faq.md)
- [å®Œæ•´ä½¿ç”¨æ‰‹å†Œ](../user-guide/user-guide.md)

### 2. ç¤¾åŒºæ”¯æŒ

**Anthropic ç¤¾åŒº**ï¼š
- [Discord æœåŠ¡å™¨](https://discord.gg/anthropic)
- [ç¤¾åŒºè®ºå›](https://community.anthropic.com/)
- [GitHub Discussions](https://github.com/anthropics/anthropic-sdk-python/discussions)

**æé—®æŠ€å·§**ï¼š
1. æä¾›å®Œæ•´çš„é”™è¯¯ä¿¡æ¯
2. åŒ…å«æœ€å°å¯å¤ç°ç¤ºä¾‹
3. è¯´æ˜å·²å°è¯•çš„è§£å†³æ–¹æ¡ˆ
4. æè¿°é¢„æœŸè¡Œä¸ºå’Œå®é™…è¡Œä¸º

### 3. æŠ€æœ¯æ”¯æŒ

**Anthropic æ”¯æŒ**ï¼š
- ä¼ä¸šå®¢æˆ·ï¼šé€šè¿‡ Anthropic Console æäº¤å·¥å•
- æŠ€æœ¯é—®é¢˜ï¼šsupport@anthropic.com
- å®‰å…¨é—®é¢˜ï¼šsecurity@anthropic.com

**AWS Bedrock æ”¯æŒ**ï¼š
- AWS Support Center
- AWS è®ºå›
- AWS æ–‡æ¡£

### 4. æŠ¥å‘Šé—®é¢˜

**æäº¤ Bug æŠ¥å‘Šæ—¶åŒ…å«**ï¼š
```
ç¯å¢ƒä¿¡æ¯ï¼š
- æ“ä½œç³»ç»Ÿï¼š
- Python ç‰ˆæœ¬ï¼š
- SDK ç‰ˆæœ¬ï¼š
- æ¨¡å‹ï¼š

é—®é¢˜æè¿°ï¼š
[è¯¦ç»†æè¿°é—®é¢˜]

å¤ç°æ­¥éª¤ï¼š
1. 
2. 
3. 

é¢„æœŸè¡Œä¸ºï¼š
[æè¿°é¢„æœŸç»“æœ]

å®é™…è¡Œä¸ºï¼š
[æè¿°å®é™…ç»“æœ]

é”™è¯¯ä¿¡æ¯ï¼š
```
[å®Œæ•´çš„é”™è¯¯æ—¥å¿—]
```

æœ€å°å¯å¤ç°ä»£ç ï¼š
```python
[æœ€ç®€å•çš„èƒ½å¤ç°é—®é¢˜çš„ä»£ç ]
```
```

---

## ç›¸å…³èµ„æº

### å®˜æ–¹èµ„æº
- [Anthropic å®˜ç½‘](https://www.anthropic.com/)
- [Claude API æ–‡æ¡£](https://docs.anthropic.com/claude/)
- [Anthropic Console](https://console.anthropic.com/)
- [çŠ¶æ€é¡µé¢](https://status.anthropic.com/)

### å¼€å‘èµ„æº
- [Python SDK](https://github.com/anthropics/anthropic-sdk-python)
- [TypeScript SDK](https://github.com/anthropics/anthropic-sdk-typescript)
- [Cookbook](https://github.com/anthropics/anthropic-cookbook)

### å­¦ä¹ èµ„æº
- [æç¤ºå·¥ç¨‹æŒ‡å—](https://docs.anthropic.com/claude/docs/prompt-engineering)
- [æœ€ä½³å®è·µ](https://docs.anthropic.com/claude/docs/best-practices)
- [ç¤ºä¾‹é¡¹ç›®](https://github.com/anthropics/anthropic-cookbook)

### ç›¸å…³æ–‡æ¡£
- [è®¾è®¡åŸç†](design-principles.md)ï¼šç†è§£é—®é¢˜èƒŒåçš„åŸç†
- [æ€§èƒ½ä¼˜åŒ–](performance.md)ï¼šæé«˜æ€§èƒ½å’Œé™ä½æˆæœ¬
- [å¸¸è§é—®é¢˜](faq.md)ï¼šå¿«é€ŸæŸ¥æ‰¾ç­”æ¡ˆ
- [API å‚è€ƒ](../user-guide/api-reference.md)ï¼šAPI è¯¦ç»†è¯´æ˜

---

**ä¸Šä¸€æ­¥**ï¼š[æ€§èƒ½ä¼˜åŒ–](performance.md)  
**ä¸‹ä¸€æ­¥**ï¼š[å¸¸è§é—®é¢˜](faq.md)

**ç›¸å…³æ–‡æ¡£**ï¼š
- [å®Œæ•´ä½¿ç”¨æ‰‹å†Œ](../user-guide/user-guide.md)
- [å®‰è£…æŒ‡å—](../getting-started/installation.md)
- [å¿«é€Ÿå¼€å§‹](../getting-started/quickstart.md)


